{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/1_cZKKqiASdIfCy_qvkZ0pSA.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution \n",
    "+ Phép tích chập:\n",
    "$$\n",
    "s(t) = (x * w)(t) = \\sum_a x(a)w(t - a) \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\text{với dữ liệu liên tục thay bằng tích phân}\n",
    "$$\n",
    "+ VD: Với dữ liệu ảnh 2D $I$, hạt nhân $K$:\n",
    "$$\n",
    "S(i, j) = (I * K)(i, j) = \\sum_m \\sum_n I(m, n) K(i - m, j -n) \\\\\n",
    "S(i, j) = (K * I)(i, j) = \\sum_m \\sum_n I(i - m,j - n) K(i, j) \\\\ \\ \\ \\ \\ \\ \\ \\ \\text{phép tích chập có tính giao hoán (thường dùng công thức này)}\n",
    "$$\n",
    "\n",
    "+ Tích chập sử dụng 3 ý tưởng chính để cải thiện hệ thống học máy:\n",
    "    + Sparse interactions (kết nối thưa)\n",
    "    + parameter sharing\n",
    "    + equivariant representation (biểu diễn tương đẳng)\n",
    "\n",
    "+ **Sparse interactions**:\n",
    "    + Các nerual network truyền thống sử dụng phép nhân ma trận\n",
    "    + Cải tiến của CNN làm cho kernel có kích thước nhỏ hơn đầu vào -> lưu trữ ít tham số hơn, giảm yêu cầu về bộ nhớ và tính toán\n",
    "\n",
    "+ **Parameter sharing**: \n",
    "    + Trong NN truyền thống, 1 ma trận trọng số chỉ sử dụng 1 lần khi tính toán đầu ra của 1 lớp\n",
    "    + Trong CNN, mỗi phần tử của kernel được sử dụng trong mọi vị trí của đầu vào -> hữu ích khi phát hiện các đặc trưng xuất hiện ở nhiều vị trí. Thay ví học 1 bộ trọng số riêng biệt cho mỗi vị trí\n",
    "\n",
    "+ **Equivariant representation**\n",
    "    + Nếu đầu vào dịch chuyển đầu ra cx dịch chuyển tương ứng theo cách giống nhau\n",
    "    + Ví dụ: Với hình ảnh, tích chập tạo ra feature map 2D, nếu chúng ta dịch chuyển đầu vào thì biểu diên  của nó dịch chuyển tương ứng ở đầu ra. Khi đối tượng có cạnh trong hình ảnh được di chuyển thì filter vẫn phát hiện cạnh đó nhưng ở vị trí mơi.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Các loại Pooling\n",
    "+ Giúp giảm kích thước feature map -> giảm tham số, tính toán\n",
    "+ Giúp giữ lại cách đặc trưng quan trọng, giảm thiểu sự nhạy cảm với thay đổi nhỏ trong đầu vào\n",
    "+ Các Pooling:\n",
    "    + Max pooling: chọn ra giá trị lớn nhất trong mỗi khối nhỏ của feature map\n",
    "    + Average pooling: giá trị trung bình trong mỗi khối nhỏ của feature map\n",
    "    + Global pooling (global max pooling hoặc global average pooling): tính toán giá trị max hoặc trung bình cho toàn bộ feature map. Điều này thường được sử dụng trước khi kết nối với lớp fully connected để giảm kích thước đầu ra.\n",
    "\n",
    "![](img/poolingwebp.webp)\n",
    "![](img/global_pooling.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flatten Layer\n",
    "\n",
    "Flatten Layer là một lớp đơn giản nhưng rất quan trọng, đặc biệt khi bạn chuyển từ các lớp convolution và pooling sang các lớp fully connected.\n",
    "\n",
    "- Cách Hoạt Động\n",
    "  - **Chuyển Đổi nhiều chiều sang 1D**: Lớp flatten chuyển đổi một tensor nhiều chiều (thường là 3D với chiều cao, chiều rộng và số lượng channel) thành một vector 1D. Ví dụ, sau các lớp convolution và pooling, bạn có thể có một tensor với kích thước $ [H \\times W \\times C] $, trong đó $ H $ là chiều cao, $ W $ là chiều rộng và $ C $ là số lượng channel. Flatten layer sẽ chuyển đổi tensor này thành một vector với chiều dài $ H \\times W \\times C $.\n",
    "  - **Đơn Giản Hóa Dữ Liệu**: Sau khi dữ liệu hình ảnh đã được trích xuất thành các đặc trưng, lớp flatten sẽ giúp đơn giản hóa dữ liệu để nó có thể được đưa vào lớp fully connected, nơi dữ liệu được xử lý như một vector thay vì một tensor nhiều chiều.\n",
    "\n",
    "- Vai Trò Trong CNN\n",
    "  - **Kết Nối Với Lớp Fully Connected**: Lớp Flatten là cầu nối giữa các lớp convolutional và lớp fully connected. Các lớp convolution và pooling thường giữ lại cấu trúc không gian của dữ liệu, nhưng lớp fully connected yêu cầu dữ liệu phải ở dạng vector phẳng. Do đó, Flatten layer giúp chuyển đổi định dạng này để phù hợp với lớp fully connected.\n",
    "  - **Ví Dụ**: Giả sử đầu vào cho lớp Flatten là một tensor với kích thước $ [7 \\times 7 \\times 512] $, sau khi Flatten, đầu ra sẽ là một vector có kích thước $ [7 \\times 7 \\times 512 = 25088] $. Vector này có thể được đưa vào một lớp fully connected.\n",
    "\n",
    "\n",
    "# Fully Connected Layer\n",
    "\n",
    "- Cách Hoạt Động\n",
    "  - Công thức toán học cho một lớp fully connected là:\n",
    "    $$\n",
    "    z = W \\cdot x + b\n",
    "    $$\n",
    "    Trong đó:\n",
    "    - $ x $ là đầu vào (vector đặc trưng từ lớp trước).\n",
    "    - $ W $ là ma trận trọng số\n",
    "    - $ b $ là vector bias\n",
    "    - $ z $ là đầu ra của lớp fully connected, thường sau đó được đưa qua activation function như ReLU, Sigmoid, hoặc Softmax.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ví dụ\n",
    "\n",
    "Xây dựng mô hình CNN phân loại xe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'vehicle/Training'\n",
    "test_dir = 'vehicle/Testing'\n",
    "\n",
    "train_dataset = ImageFolder(train_dir, transform=transforms.Compose([transforms.Resize((128,128)), transforms.ToTensor()]))\n",
    "test_dataset = train_dataset = ImageFolder(test_dir, transform=transforms.Compose([transforms.Resize((128,128)), transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 128, 128])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, label = train_dataset[0]\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bus', 'car', 'moto', 'pedestrian', 'truck']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "val_size = int(len(train_dataset) * 0.3)\n",
    "train_size = len(train_dataset) - val_size\n",
    "train_data, val_data = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "train_dl = DataLoader(train_data, batch_size, shuffle=True)\n",
    "val_dl = DataLoader(val_data, batch_size, shuffle=True)\n",
    "test_dl = DataLoader(test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCNN(nn.Module):\n",
    "    def __init__(self ):\n",
    "        super(MyCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride = 1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride = 1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.fl = nn.Flatten()\n",
    "\n",
    "        self.fc1 = nn.Linear(64 * 14 * 14, 1024)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(1024, 256)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(256, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.pool1(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.pool2(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.relu3(out)\n",
    "        out = self.pool3(out)\n",
    "\n",
    "        out = self.fl(out)\n",
    "\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu4(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu5(out)\n",
    "        out = self.fc3(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataloder, val_dataloader,  num_epochs, opt_func = optim.Adam, lr = 0.01):\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for i in range(num_epochs):\n",
    "        model.train()\n",
    "\n",
    "        train_loss_epoch = 0.0\n",
    "        val_loss_epoch = 0.0\n",
    "\n",
    "        for batch_X, batch_y in train_dataloder:\n",
    "\n",
    "            output = model(batch_X)\n",
    "            loss = criterion(output, batch_y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss_epoch += loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for X_val, y_val in val_dataloader:\n",
    "                output = model(X_val)\n",
    "                loss = F.cross_entropy(output, y_val)\n",
    "                val_loss_epoch += loss.item()\n",
    "\n",
    "        avg_train_loss = train_loss_epoch / len(train_dataloder)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        avg_val_loss = val_loss_epoch / len(val_dataloader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        print(f\"Epoch {i + 1} / {num_epochs}: train loss: {avg_train_loss}, val loss: {avg_val_loss}\")\n",
    "\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 100: train loss: 7.689721012115479, val loss: 1.5368870496749878\n",
      "Epoch 2 / 100: train loss: 1.6073374509811402, val loss: 1.5111468434333801\n",
      "Epoch 3 / 100: train loss: 1.5897489547729493, val loss: 1.6547085046768188\n",
      "Epoch 4 / 100: train loss: 1.626796817779541, val loss: 1.550927221775055\n",
      "Epoch 5 / 100: train loss: 1.5578304767608642, val loss: 1.5093839764595032\n",
      "Epoch 6 / 100: train loss: 1.6439351797103883, val loss: 1.5007765293121338\n",
      "Epoch 7 / 100: train loss: 1.590745759010315, val loss: 1.5467860698699951\n",
      "Epoch 8 / 100: train loss: 1.6070869445800782, val loss: 1.5539231300354004\n",
      "Epoch 9 / 100: train loss: 1.5667400121688844, val loss: 1.5610191226005554\n",
      "Epoch 10 / 100: train loss: 1.5721670627593993, val loss: 1.5497498512268066\n",
      "Epoch 11 / 100: train loss: 1.6000787258148192, val loss: 1.5291836857795715\n",
      "Epoch 12 / 100: train loss: 1.6770551681518555, val loss: 1.5149553418159485\n",
      "Epoch 13 / 100: train loss: 1.5438856840133668, val loss: 1.524292528629303\n",
      "Epoch 14 / 100: train loss: 1.4883149147033692, val loss: 1.3953580260276794\n",
      "Epoch 15 / 100: train loss: 1.5163669824600219, val loss: 1.5176644921302795\n",
      "Epoch 16 / 100: train loss: 1.5811103105545044, val loss: 1.5363447666168213\n",
      "Epoch 17 / 100: train loss: 1.5565691947937013, val loss: 1.5060795545578003\n",
      "Epoch 18 / 100: train loss: 1.403192138671875, val loss: 1.4538190364837646\n",
      "Epoch 19 / 100: train loss: 1.471242618560791, val loss: 1.328589141368866\n",
      "Epoch 20 / 100: train loss: 1.1770967304706574, val loss: 1.055934190750122\n",
      "Epoch 21 / 100: train loss: 0.9416521340608597, val loss: 1.5179123282432556\n",
      "Epoch 22 / 100: train loss: 1.1587470889091491, val loss: 0.8878349959850311\n",
      "Epoch 23 / 100: train loss: 0.9184738874435425, val loss: 0.6914642751216888\n",
      "Epoch 24 / 100: train loss: 0.7862953543663025, val loss: 0.6703134775161743\n",
      "Epoch 25 / 100: train loss: 0.5778047621250153, val loss: 0.5464814901351929\n",
      "Epoch 26 / 100: train loss: 0.6908949494361878, val loss: 0.5370606034994125\n",
      "Epoch 27 / 100: train loss: 0.560590535402298, val loss: 0.7129521369934082\n",
      "Epoch 28 / 100: train loss: 0.34839546084385803, val loss: 0.7045154273509979\n",
      "Epoch 29 / 100: train loss: 0.3718932846444659, val loss: 0.7366775125265121\n",
      "Epoch 30 / 100: train loss: 0.29246262516826393, val loss: 0.8114006221294403\n",
      "Epoch 31 / 100: train loss: 0.4011608200613409, val loss: 0.5421160310506821\n",
      "Epoch 32 / 100: train loss: 0.2931445669848472, val loss: 0.46129292249679565\n",
      "Epoch 33 / 100: train loss: 0.17496401853859425, val loss: 0.39720986783504486\n",
      "Epoch 34 / 100: train loss: 0.2440422922372818, val loss: 0.6646892130374908\n",
      "Epoch 35 / 100: train loss: 0.278574187560298, val loss: 1.0132618844509125\n",
      "Epoch 36 / 100: train loss: 0.5368118643760681, val loss: 0.8504837155342102\n",
      "Epoch 37 / 100: train loss: 0.29315889775753023, val loss: 0.7566232979297638\n",
      "Epoch 38 / 100: train loss: 0.2082416776334867, val loss: 0.7904791384935379\n",
      "Epoch 39 / 100: train loss: 0.1296604797244072, val loss: 0.9583074152469635\n",
      "Epoch 40 / 100: train loss: 0.0830822791904211, val loss: 0.8572320938110352\n",
      "Epoch 41 / 100: train loss: 0.05956773515790701, val loss: 1.0108637511730194\n",
      "Epoch 42 / 100: train loss: 0.027258765505575867, val loss: 1.1257484555244446\n",
      "Epoch 43 / 100: train loss: 0.08287634453736245, val loss: 3.6417532563209534\n",
      "Epoch 44 / 100: train loss: 0.5736571410205216, val loss: 1.3050549626350403\n",
      "Epoch 45 / 100: train loss: 0.604822826385498, val loss: 0.8472208976745605\n",
      "Epoch 46 / 100: train loss: 0.5170660972595215, val loss: 1.0465832352638245\n",
      "Epoch 47 / 100: train loss: 0.6810835838317871, val loss: 1.6118261218070984\n",
      "Epoch 48 / 100: train loss: 0.4088757887482643, val loss: 0.9531449973583221\n",
      "Epoch 49 / 100: train loss: 0.15601974427659115, val loss: 1.3630105257034302\n",
      "Epoch 50 / 100: train loss: 0.5420105457305908, val loss: 0.710186317563057\n",
      "Epoch 51 / 100: train loss: 0.19306528493762015, val loss: 0.6904193460941315\n",
      "Epoch 52 / 100: train loss: 0.11954491117503493, val loss: 0.8063726276159286\n",
      "Epoch 53 / 100: train loss: 0.06629560698056594, val loss: 0.7817397117614746\n",
      "Epoch 54 / 100: train loss: 0.0206295901662088, val loss: 0.7446170896291733\n",
      "Epoch 55 / 100: train loss: 0.017218828527256848, val loss: 0.9044206142425537\n",
      "Epoch 56 / 100: train loss: 0.05539064465556294, val loss: 0.9514981210231781\n",
      "Epoch 57 / 100: train loss: 0.007163604628294707, val loss: 1.1569072902202606\n",
      "Epoch 58 / 100: train loss: 0.0590343274137922, val loss: 1.1765756607055664\n",
      "Epoch 59 / 100: train loss: 0.04753839075565338, val loss: 1.0874272882938385\n",
      "Epoch 60 / 100: train loss: 0.00551647694373969, val loss: 1.2921573519706726\n",
      "Epoch 61 / 100: train loss: 0.0030445494047853573, val loss: 1.2305309176445007\n",
      "Epoch 62 / 100: train loss: 0.0002532847585825948, val loss: 1.282427966594696\n",
      "Epoch 63 / 100: train loss: 0.002216159433601206, val loss: 1.115888625383377\n",
      "Epoch 64 / 100: train loss: 0.0005206845190514287, val loss: 1.2446492314338684\n",
      "Epoch 65 / 100: train loss: 7.315583404761128e-05, val loss: 1.4993724822998047\n",
      "Epoch 66 / 100: train loss: 0.00010230415809928673, val loss: 1.3698642253875732\n",
      "Epoch 67 / 100: train loss: 5.646734498441219e-05, val loss: 1.5434736609458923\n",
      "Epoch 68 / 100: train loss: 5.2071114487262095e-05, val loss: 1.4030924439430237\n",
      "Epoch 69 / 100: train loss: 4.382524221000494e-05, val loss: 1.5191340744495392\n",
      "Epoch 70 / 100: train loss: 4.022293273919786e-05, val loss: 1.3214367032051086\n",
      "Epoch 71 / 100: train loss: 3.693558392114937e-05, val loss: 1.3728148341178894\n",
      "Epoch 72 / 100: train loss: 3.333697732159635e-05, val loss: 1.3921117782592773\n",
      "Epoch 73 / 100: train loss: 3.055356855838909e-05, val loss: 1.5960072576999664\n",
      "Epoch 74 / 100: train loss: 2.8217979433975415e-05, val loss: 1.4087804555892944\n",
      "Epoch 75 / 100: train loss: 2.5425355988772936e-05, val loss: 1.3079219460487366\n",
      "Epoch 76 / 100: train loss: 2.3969417179614537e-05, val loss: 1.428031861782074\n",
      "Epoch 77 / 100: train loss: 2.2396912527256063e-05, val loss: 1.3679031133651733\n",
      "Epoch 78 / 100: train loss: 2.0838480611473643e-05, val loss: 1.5588566362857819\n",
      "Epoch 79 / 100: train loss: 1.9098570555797777e-05, val loss: 1.4842687249183655\n",
      "Epoch 80 / 100: train loss: 1.797007782897708e-05, val loss: 1.518231749534607\n",
      "Epoch 81 / 100: train loss: 1.7047105393430685e-05, val loss: 1.270839884877205\n",
      "Epoch 82 / 100: train loss: 1.6182794411179202e-05, val loss: 1.4240426421165466\n",
      "Epoch 83 / 100: train loss: 1.530731300363186e-05, val loss: 1.4740700125694275\n",
      "Epoch 84 / 100: train loss: 1.4580770346128702e-05, val loss: 1.4234172105789185\n",
      "Epoch 85 / 100: train loss: 1.3932938691141316e-05, val loss: 1.6826879680156708\n",
      "Epoch 86 / 100: train loss: 1.3373882541145577e-05, val loss: 1.5918216109275818\n",
      "Epoch 87 / 100: train loss: 1.546567273180699e-05, val loss: 1.545239508152008\n",
      "Epoch 88 / 100: train loss: 1.2178811880403373e-05, val loss: 1.5905483961105347\n",
      "Epoch 89 / 100: train loss: 1.1606138377828756e-05, val loss: 1.4922534823417664\n",
      "Epoch 90 / 100: train loss: 1.209439285503322e-05, val loss: 1.4602355360984802\n",
      "Epoch 91 / 100: train loss: 1.164087193501473e-05, val loss: 1.3663453459739685\n",
      "Epoch 92 / 100: train loss: 0.00011703223686936326, val loss: 1.578374981880188\n",
      "Epoch 93 / 100: train loss: 9.39821038627997e-06, val loss: 1.439453363418579\n",
      "Epoch 94 / 100: train loss: 8.69445161697513e-06, val loss: 1.574805736541748\n",
      "Epoch 95 / 100: train loss: 8.354895271622809e-06, val loss: 1.5957521796226501\n",
      "Epoch 96 / 100: train loss: 7.768772650251777e-06, val loss: 1.5939512252807617\n",
      "Epoch 97 / 100: train loss: 7.430602749991522e-06, val loss: 1.6343708038330078\n",
      "Epoch 98 / 100: train loss: 6.585524606634862e-05, val loss: 1.4919636249542236\n",
      "Epoch 99 / 100: train loss: 6.723072037573275e-06, val loss: 1.4565815329551697\n",
      "Epoch 100 / 100: train loss: 6.978034866733651e-06, val loss: 1.3357033655047417\n"
     ]
    }
   ],
   "source": [
    "model = MyCNN()\n",
    "train_losses, val_losses = train(model, train_dl, val_dl, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy test: 0.9508\n"
     ]
    }
   ],
   "source": [
    "test_dl = DataLoader(test_dataset, batch_size=(len(test_dataset)), shuffle=False)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_y in test_dl:    \n",
    "        outputs = model(batch_X)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        accuracy = (predicted == batch_y).sum().item() / batch_y.size(0)\n",
    "        print(f'Accuracy test: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
